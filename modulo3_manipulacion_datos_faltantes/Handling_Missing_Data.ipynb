{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPb0J8nnEy7f5nXbntdTLzn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/john-caballero/Data-Discovery/blob/main/modulo3_manipulacion_datos_faltantes/Handling_Missing_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://posgrado.utec.edu.pe/sites/default/files/2023-08/Testimonial-home-2.jpg\" alt=\"HTML5 Icon\" width=\"900\" height=\"250\" >\n"
      ],
      "metadata": {
        "id": "63Z52XtzaaqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Handling Missing Data**"
      ],
      "metadata": {
        "id": "nXzKdHNnalF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objetivos**\n",
        "\n",
        "- Aplicar distintas t茅cnicas de imputaci贸n:\n",
        "\n",
        "  - Medidas de tendencia central (media, mediana, moda)\n",
        "\n",
        "  - Imputaci贸n por regresi贸n\n",
        "\n",
        "  - KNN imputation\n",
        "\n",
        "  - XGBoost imputador\n",
        "\n",
        "  - Autoencoders\n",
        "\n",
        "  - MICE (Multiple Imputation by Chained Equations)\n",
        "\n",
        "- Entrenar un modelo base (RandomForest o XGBoost) para comparar el impacto de cada estrategia de imputaci贸n en t茅rminos de performance (accuracy, AUC, etc.)\n",
        "\n",
        "- Reflexionar sobre las implicancias de cada m茅todo para modelos anal铆ticos."
      ],
      "metadata": {
        "id": "l3bhQt_IalxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset**\n",
        "\n",
        "Loan Prediction - train.csv\n",
        "\n",
        "Puedes obtenerlo desde:\n",
        " https://datahack.analyticsvidhya.com/contest/practice-problem-loan-prediction-iii"
      ],
      "metadata": {
        "id": "Inh96ly5azO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Librer铆as necesarias"
      ],
      "metadata": {
        "id": "rvo1B-sea4nN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy seaborn matplotlib scikit-learn xgboost fancyimpute tensorflow missingno\n"
      ],
      "metadata": {
        "id": "RPK6gi4ka6Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Carga y diagn贸stico inicial"
      ],
      "metadata": {
        "id": "wOP8Iso2a8uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "df.drop(\"Loan_ID\", axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "8katKHaya_1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Medidas de tendencia central (media, mediana, moda)"
      ],
      "metadata": {
        "id": "LodYmLpGbCZl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80twajk3aaHM"
      },
      "outputs": [],
      "source": [
        "df_mean = df.copy()\n",
        "\n",
        "df_mean[\"LoanAmount\"].fillna(df_mean[\"LoanAmount\"].mean(), inplace=True)\n",
        "df_mean[\"Gender\"].fillna(df_mean[\"Gender\"].mode()[0], inplace=True)\n",
        "df_mean[\"Self_Employed\"].fillna(df_mean[\"Self_Employed\"].mode()[0], inplace=True)\n",
        "df_mean[\"Dependents\"].fillna(df_mean[\"Dependents\"].mode()[0], inplace=True)\n",
        "df_mean[\"Credit_History\"].fillna(df_mean[\"Credit_History\"].mode()[0], inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Imputaci贸n por regresi贸n lineal"
      ],
      "metadata": {
        "id": "wQLWxMqmbK1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "df_reg = df.copy()\n",
        "train = df_reg[df_reg[\"LoanAmount\"].notnull()]\n",
        "test = df_reg[df_reg[\"LoanAmount\"].isnull()]\n",
        "\n",
        "X_train = train[[\"ApplicantIncome\", \"CoapplicantIncome\"]]\n",
        "y_train = train[\"LoanAmount\"]\n",
        "X_test = test[[\"ApplicantIncome\", \"CoapplicantIncome\"]]\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "df_reg.loc[df_reg[\"LoanAmount\"].isnull(), \"LoanAmount\"] = preds\n"
      ],
      "metadata": {
        "id": "7BZ1G8k0bODa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.  Imputaci贸n KNN"
      ],
      "metadata": {
        "id": "YFnm0CuwbQi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df_knn = df.copy()\n",
        "df_knn = df_knn.apply(LabelEncoder().fit_transform)\n",
        "\n",
        "knn_imputer = KNNImputer(n_neighbors=5)\n",
        "df_knn_imputed = pd.DataFrame(knn_imputer.fit_transform(df_knn), columns=df_knn.columns)\n"
      ],
      "metadata": {
        "id": "IZtvpYFybUN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Imputaci贸n con XGBoost (modelo para imputar)"
      ],
      "metadata": {
        "id": "6BS0jGpibWTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "df_xgb = df.copy()\n",
        "\n",
        "def xgb_impute(df, target_col):\n",
        "    train = df[df[target_col].notnull()]\n",
        "    test = df[df[target_col].isnull()]\n",
        "    features = [col for col in df.columns if col != target_col and df[col].notnull().sum() > 0]\n",
        "\n",
        "    train = train.dropna(subset=features)\n",
        "    X_train = pd.get_dummies(train[features])\n",
        "    y_train = train[target_col]\n",
        "    X_test = pd.get_dummies(test[features])\n",
        "    X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
        "\n",
        "    model = xgb.XGBRegressor(n_estimators=100)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "\n",
        "    df.loc[df[target_col].isnull(), target_col] = preds\n",
        "    return df\n",
        "\n",
        "df_xgb = xgb_impute(df_xgb, \"LoanAmount\")\n"
      ],
      "metadata": {
        "id": "bg-F6wCNba5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Imputaci贸n MICE (Multivariate Imputation)"
      ],
      "metadata": {
        "id": "Wu8e7VBcbc27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fancyimpute import IterativeImputer\n",
        "\n",
        "df_mice = df.copy()\n",
        "df_mice = df_mice.apply(LabelEncoder().fit_transform)\n",
        "\n",
        "mice = IterativeImputer()\n",
        "df_mice_imputed = pd.DataFrame(mice.fit_transform(df_mice), columns=df_mice.columns)\n"
      ],
      "metadata": {
        "id": "Tf_DU7a4bfZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Autoencoders para imputaci贸n"
      ],
      "metadata": {
        "id": "rUCnwkphbhF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "df_auto = df.copy()\n",
        "df_auto = df_auto.apply(LabelEncoder().fit_transform)\n",
        "df_auto = df_auto.fillna(df_auto.mean())\n",
        "\n",
        "X = df_auto.values\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(X.shape[1],)),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(X.shape[1])\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(X, X, epochs=100, batch_size=16, verbose=0)\n",
        "\n",
        "X_pred = model.predict(X)\n",
        "df_auto_imputed = pd.DataFrame(X_pred, columns=df_auto.columns)\n"
      ],
      "metadata": {
        "id": "vt8RT8IBbiuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Evaluaci贸n del impacto predictivo\n",
        "\n",
        "Utilizaremos un modelo de clasificaci贸n (XGBClassifier) para predecir Loan_Status con los diferentes datasets imputados."
      ],
      "metadata": {
        "id": "LdSdwVFKbm0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "def evaluate_model(df, name=\"\"):\n",
        "    df = df.copy()\n",
        "    df = df.dropna()\n",
        "    X = df.drop(\"Loan_Status\", axis=1)\n",
        "    y = df[\"Loan_Status\"]\n",
        "\n",
        "    if y.dtype == 'O':\n",
        "        y = LabelEncoder().fit_transform(y)\n",
        "\n",
        "    X = pd.get_dummies(X)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    preds = model.predict(X_test)\n",
        "    probas = model.predict_proba(X_test)[:,1]\n",
        "\n",
        "    print(f\" Evaluaci贸n con {name}\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, preds):.4f}\")\n",
        "    print(f\"AUC: {roc_auc_score(y_test, probas):.4f}\\n\")\n",
        "\n",
        "# Evaluar\n",
        "evaluate_model(df_mean, \"Media/Moda\")\n",
        "evaluate_model(df_reg, \"Regresi贸n\")\n",
        "evaluate_model(df_knn_imputed, \"KNN\")\n",
        "evaluate_model(df_xgb, \"XGBoost\")\n",
        "evaluate_model(df_mice_imputed, \"MICE\")\n",
        "evaluate_model(df_auto_imputed, \"Autoencoder\")\n"
      ],
      "metadata": {
        "id": "KAmNaCV7brsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preguntas para reflexi贸n\n",
        "\n",
        "- 驴Qu茅 t茅cnica ofrece mejor balance entre simplicidad y precisi贸n?\n",
        "\n",
        "- 驴Qu茅 riesgos podr铆a implicar usar una t茅cnica muy compleja como Autoencoders o XGBoost para imputar?\n",
        "\n",
        "- 驴Por qu茅 KNN puede ser sensible a la escala de los datos o a outliers?\n",
        "\n",
        "- 驴C贸mo se podr铆a incorporar la incertidumbre de la imputaci贸n en el modelo final?\n",
        "\n",
        "- 驴Qu茅 tipo de datos (categ贸ricos, num茅ricos, multivariados) favorecen el uso de MICE sobre otros m茅todos?"
      ],
      "metadata": {
        "id": "vDWnUyhrb44e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusi贸n\n",
        "\n",
        "La imputaci贸n no es solo un paso t茅cnico: es una decisi贸n anal铆tica que puede alterar el resultado del modelo. Evaluar diferentes m茅todos no solo mejora el desempe帽o, sino tambi茅n la confianza en los modelos desarrollados. Entender cu谩ndo usar cada t茅cnica y su impacto es clave para un an谩lisis responsable."
      ],
      "metadata": {
        "id": "QVfOuKovb-94"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Gracias por completar este laboratorio!\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "cDjdWiDRcDSI"
      }
    }
  ]
}